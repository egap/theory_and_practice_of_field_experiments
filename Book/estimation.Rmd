# Estimands and Estimators {.tabset}

Randomized experiments generate good guesses about the average outcome under treatment and the average outcome under control.  This allows us to write down unbiased estimators of average treatment effects.  We can also use the randomization to describe how estimates generated by an estimator can vary from experiment to experiment in the form of standard errors and confidence intervals.

In this module, we introduce several types of estimands, the target quantity to be estimated.  The choice of estimand is a scientific and policy-informed decision -- what quantity is useful for us to learn about?  In addition, we want to select an appropriate estimator for this estimand as part of the research design.  We discuss how estimators are applied to data to generate an estimate of our estimand and how to characterize the variability of this estimate.   


## Core Content

- A **causal effect**, $\tau_i$, is a comparison of unobserved potential outcomes for each unit $i$.  For example, this can be a difference or a ratio of unobserved potential outcomes.  

- To learn about $\tau_{i}$, we can treat $\tau_{i}$ as an **estimand** or target quantity to be estimated (this module) or as a target quantity to be hypothesized about ([hypothesis testing module](hypothesis-testing.html)).

- Many focus on the **average treatment effect (ATE)**, $\bar{\tau}=\sum_{i=1}^n
   \tau_{i}$, in part, because it allows for easy **estimation**.

- An **estimator** is a recipe for calculating a guess about the value of an estimand. For example, the difference between the mean of observed outcomes for $m$ treated units and the mean of observed outcomes for $N-m$ untreated units is one estimator of $\bar{\tau}$. 

- Different randomizations will produce different values of the same estimator targeting the same estimand. A **standard error** summarizes this variability in an estimator.

- A $100(1-\alpha)$% **confidence interval** is a collection of hypotheses that cannot be rejected at the $\alpha$ level. We tend to report confidence intervals containing hypotheses about values of our estimand and use our estimator as a test statistic.

- Estimators should (1) avoid systematic error in their guessing of the estimand (be unbiased); (2) vary little in their guesses from experiment to experiment (be precise or efficient); and perhaps ideally (3) converge to the estimand as they use more  and more information (be consistent).

 - **Analyze as you randomize** in the context of estimation means that (1) our standard errors should measure the variability from randomization and (2) our estimators should target estimands defined in terms of potential outcomes.

 - We do not **control for** background covariates when we analyze data from randomized experiments. But covariates can make our estimation more **precise**. This is called **covariance adjustment**. Covariance adjustment in randomized experiments differs from controlling for variables in observational studies.

 - A policy intervention (like a letter that encourages exercise) may *intend* to change behavior via an **active dose** (actual exercise). We can learn about the causal effect of the intention by randomly assigning letters; this is the **intent to treat effect, ITT**. 
 
 - We can learn about the causal effect of actual exercise by using the random assignment of letters as an **instrument** for the active dose (exercise itself) in order to learn about the causal effect of exercise **among those who would change their behavior after receiving the letter**. The average causal effect versions of these effects are often known as the **complier average causal effect** or the **local average treatment effect**.



## Slides

Below are slides with the core content that we cover in this session.

- [R Markdown Source](https://egap.github.io/learningdays-resources/Slides/estimation-slides.Rmd)

- [PDF Version](https://egap.github.io/learningdays-resources/Slides/estimation-slides.pdf)

- [HTML Version](https://egap.github.io/learningdays-resources/Slides/estimation-slides.html)

You can also see the slides used in previous EGAP Learning Days:

 - [The estimation presentation from EGAP Learning Days at the African School of Economics, Abomey-Calavi, June 2019](https://egap.github.io/learningdays-resources/Slides/Examples/estimation-benin.pdf)

 - [The estimation presentation from EGAP Learning Days at Universidad de Los Andes, Bogotá, April 2019](https://egap.github.io/learningdays-resources/Slides/Examples/estimation-bogota.pdf)

 - [The estimation presentation from EGAP Learning Days at Universidad Católica del Uruguay, Montevideo, March 2018](https://egap.github.io/learningdays-resources/Slides/Examples/estimation-montevideo.pdf)

 - [The estimation presentation from EGAP Learning Days at Universidad Diego Portales in Santiago, Chile, May 2016](https://egap.github.io/learningdays-resources/Slides/Examples/estimation-santiago.pdf)

You can also see discussion of the problems of estimating the effect of the active dose of a treatment in these slides (as well as discussion of the problems that missing data on outcomes cause for estimation of average causal effects):

- [The design issues presentation from EGAP Learning Days at the African School of Economics, Abomey-Calavi, June 2019 (first section reviews randomization designs)](https://egap.github.io/learningdays-resources/Slides/Examples/threats-benin.pdf)

- [The spillovers and attrition presentation from EGAP Learning Days in Guatemala City, Guatemala, August 2017](https://egap.github.io/learningdays-resources/Slides/Examples/spillovers_attrition-guatemala.pdf)

- [The threats presentation from EGAP Learning Days in Guatemala City, Guatemala, August 2017](https://egap.github.io/learningdays-resources/Slides/Examples/threats-guatemala.pdf)

- [The complications presentation from EGAP Learning Days in Salima, Malawi, February 2017](https://egap.github.io/learningdays-resources/Slides/Examples/complications-malawi.pdf)

- [The threats presentation from EGAP Learning Days at Universidad Diego Portales in Santiago, Chile, May 2016 (the middle section reviews ITT and non-compliance )](https://egap.github.io/learningdays-resources/Slides/Examples/threats-santiago.pdf)


## Resources

### EGAP Methods Guides

 - EGAP Methods Guide [10 Types of Treatment Effect You Should Know About](https://egap.org/resource/10-types-of-treatment-effect-you-should-know-about/)

 - EGAP Methods Guide [10 Things to Know about Covariate Adjustment](https://egap.org/resource/10-things-to-know-about-covariate-adjustment/)

 - EGAP Methods Guide [10 Things to Know about Missing Data](https://egap.org/resource/10-things-to-know-about-missing-data/)

 - EGAP Methods Guide [10 Things to Know about the Local Average Treatment Effect](https://egap.org/resource/10-things-to-know-about-the-local-average-treatment-effect/)

 - EGAP Methods Guide [10 Things to Know about Spillovers](https://egap.org/resource/10-things-to-know-about-spillovers/)

### Books, Chapters, and Articles

 - [@gerber_field_2012]. Chapter 2.7 on excludability and non-interference, Chapter 3, Chapter 5 on one-sided noncompliance, Chapter 6 on two-sided noncompliance, Chapter 7 on attrition, Chapter 8 on interference between experimental units.

 - [@bowers2020causality].


### Tools

- [DeclareDesign](https://declaredesign.org)

- [estimatr package for R](https://declaredesign.org/r/estimatr/)

